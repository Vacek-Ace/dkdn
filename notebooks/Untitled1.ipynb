{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7749c54a-1f32-4264-8b5d-fc856b1b9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fcb92c-cc0a-4356-bc3a-a1f5d17eb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from src.model.dkdn import *\n",
    "from src.model.instance_hardness import *\n",
    "from src.model.support_subset import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e826da80-af9d-422b-9669-1203b4c27486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: banknote\n",
      "\n",
      "Incemental :  0.5\n",
      "Heuristic thresholds computation ... \n",
      "Support subset estimation ... \n",
      "0.1\n",
      "{0: 27, 1: 27}\n",
      "1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m ss_idx, ini_performance \u001b[38;5;241m=\u001b[39m sampling_heuristic(complexity_ini, X_ini, y_ini, clf, thresholds_ini, random_state\u001b[38;5;241m=\u001b[39mrng_seed, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Incremental data evaluation\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_ini\u001b[49m\u001b[43m[\u001b[49m\u001b[43mss_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mss_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m pred_incr \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_incr)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Incremental data sampling\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ss/lib/python3.9/site-packages/sklearn/svm/_base.py:199\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    191\u001b[0m         X,\n\u001b[1;32m    192\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[0;32m--> 199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    204\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[0;32m~/anaconda3/envs/ss/lib/python3.9/site-packages/sklearn/svm/_base.py:720\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes has to be greater than one; got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    723\u001b[0m     )\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "experiment = 'banknote'\n",
    "print(f'Experiment: {experiment}\\n')\n",
    "\n",
    "results_folder = '../results/incremental'\n",
    "\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "data = pd.read_parquet(f'../data/{experiment}.parquet')\n",
    "\n",
    "exp_info = {experiment:{}}\n",
    "\n",
    "# Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data.drop(columns=['y']))\n",
    "y = data.y.values\n",
    "y[y == -1] = 0\n",
    "y = y.astype(int)\n",
    "\n",
    "# Save test to evaluate models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)\n",
    "for incr in range(5, 10):\n",
    "    # Incremental data\n",
    "    incr = round(1-incr*0.1, 1)\n",
    "    print('Incemental : ', incr)\n",
    "    # Division initial set and incremental set\n",
    "    X_ini, X_incr, y_ini, y_incr = train_test_split(X_train, y_train, test_size=incr, stratify=y_train, random_state=42)\n",
    "\n",
    "    # random seed for random methods\n",
    "    rng_seed = 1234\n",
    "\n",
    "    # Heuristic thresholds\n",
    "    print('Heuristic thresholds computation ... ')\n",
    "    complexity_ini, higher_complexity_ini = complexity_high_class(X_ini, y_ini)\n",
    "    thresholds_ini = expected_performance_thresholds(higher_complexity_ini)\n",
    "\n",
    "    exp_info[experiment][incr] = {}\n",
    "\n",
    "    # Read data info\n",
    "    with open(f'../results/sampling/{experiment}.json', 'r') as fin:\n",
    "                    exp_summary = json.load(fin)\n",
    "    methods = [SVC, KNeighborsClassifier, RandomForestClassifier]\n",
    "\n",
    "    for method in methods:\n",
    "        # Method setup\n",
    "        str_method = str(method())[:-2]\n",
    "        params = exp_summary[str_method]['best_params']\n",
    "        clf = method(**params)\n",
    "\n",
    "        # Support subset estimation\n",
    "        print('Support subset estimation ... ')\n",
    "        ss_idx, ini_performance = sampling_heuristic(complexity_ini, X_ini, y_ini, clf, thresholds_ini, random_state=rng_seed, verbose=True)\n",
    "\n",
    "        # Incremental data evaluation\n",
    "        clf.fit(X_ini[ss_idx], y_ini[ss_idx])\n",
    "        pred_incr = clf.predict(X_incr)\n",
    "\n",
    "        # Incremental data sampling\n",
    "        if not (scaled_mcc(y_incr, pred_incr) > ini_performance) | (scaled_mcc(y_incr, pred_incr) > thresholds_ini[0]):\n",
    "            print('Incremental data thresholds computation ...')\n",
    "            complexity_incr, higher_complexity_incr = complexity_high_class(X_incr, y_incr)\n",
    "            thresholds_incr = expected_performance_thresholds(higher_complexity_incr)\n",
    "            print('Incremental sampling ...')\n",
    "            incr_idx, incr_performance = sampling_heuristic(complexity_incr, X_incr, y_incr, clf, thresholds_incr, random_state=rng_seed, verbose=True)\n",
    "            # New data to train model\n",
    "            X_new = np.append(X_ini[ss_idx], X_incr[incr_idx], axis=0)\n",
    "            y_new = np.append(y_ini[ss_idx], y_incr[incr_idx], axis=0)\n",
    "        else:\n",
    "            X_new = X_ini[ss_idx]\n",
    "            y_new = y_ini[ss_idx]\n",
    "\n",
    "        # Train new model\n",
    "        clf.fit(X_new, y_new)\n",
    "\n",
    "        # Performances computation\n",
    "        new_performance = scaled_mcc(y_new, clf.predict(X_new))\n",
    "        incr_performance = scaled_mcc(y_incr, clf.predict(X_incr))\n",
    "        test_performance = scaled_mcc(y_test, clf.predict(X_test))\n",
    "\n",
    "        method_info = {'proporcion': len(X_new)/len(X_train),\n",
    "        'test goal': exp_summary[str_method]['test_score'],\n",
    "        'test performance': test_performance,\n",
    "        'new performance': new_performance,\n",
    "        'ini performance': ini_performance,\n",
    "        'incr performance': incr_performance,\n",
    "        'ini thresholds': thresholds_ini,\n",
    "        'incr thresholds': thresholds_incr}\n",
    "        print(f'{str_method}: {method_info}')\n",
    "        exp_info[experiment][incr][str_method] = method_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25a873a-8b6c-423d-99ce-ec61b495a487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 54}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ss] *",
   "language": "python",
   "name": "conda-env-ss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
